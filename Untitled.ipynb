{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalVectorLoss(y_true, y_pred):\n",
    "    grad_true = tf.image.sobel_edges(y_true)\n",
    "    grad_pred = tf.image.sobel_edges(y_pred)\n",
    "    grad_true_x, grad_true_y = grad_true[...,0], grad_true[...,1]\n",
    "    grad_pred_x, grad_pred_y = grad_pred[...,0], grad_pred[...,1]\n",
    "    \n",
    "    n_g = concatenate([-grad_true_x, -grad_true_y, K.ones_like(grad_true_x)],axis=-1)\n",
    "    n_d = concatenate([-grad_pred_x, -grad_pred_y, K.ones_like(grad_pred_x)],axis=-1)\n",
    "    \n",
    "    loss = keras.losses.cosine(n_d, n_g)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradLoss(y_true, y_pred):\n",
    "    e = K.abs(y_true - y_pred)\n",
    "    grad_e = tf.image.sobel_edges(e)\n",
    "    grad_ex, grad_ey = grad_e[...,0], grad_e[...,1]\n",
    "    loss = K.mean(grad_ex + grad_ey, axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradLogLoss(y_true, y_pred):\n",
    "    e = K.abs(y_true - y_pred)\n",
    "    grad_e = tf.image.sobel_edges(e)\n",
    "    grad_ex, grad_ey = grad_e[...,0], grad_e[...,1]\n",
    "    loss = K.mean(K.log(grad_ex) + K.log(grad_ey), axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthLoss(y_true, y_pred):\n",
    "    e = K.abs(y_true - y_pred)\n",
    "    loss = K.mean(e, axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthLogLoss(y_true, y_pred):\n",
    "    e = K.log(K.abs(y_true - y_pred) + 0.5)\n",
    "    loss = K.mean(e, axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedLoss(y_true, y_pred, losses, weights):\n",
    "    assert(len(losses) == len(weights))\n",
    "    loss_ = weights[0] * losses[0](y_true, y_pred)\n",
    "    for i, loss in enumerate(losses[1:]):\n",
    "        loss_ = loss_ + weights[i+1] * loss(y_true, y_pred)\n",
    "    return loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the losses you wish to combine and corresponding weights in 2 lists\n",
    "list_losses = [gradLoss, normalVectorLoss, depthLoss]\n",
    "list_weights = [.2, .3, 1.]\n",
    "loss = partial(weightedLoss, losses=list_losses, weights=list_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just pass the function 'loss' to model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
